{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2bb56447-9f23-4072-8a7a-50030ac3feb7",
   "metadata": {},
   "source": [
    "### Neural Network implemented from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd90fa21-eb63-4488-8795-f39d8c665299",
   "metadata": {},
   "source": [
    "Simple Neural Network consists of 2 layers:\n",
    "\n",
    "- Hidden Layer\n",
    "- Output Layer\n",
    "\n",
    "\n",
    "First Initialize the size of layers along with the weights & biases.\n",
    "\n",
    "And also define the sigmoid activation function & it's derivative which is really key to introduce non-linearity.\n",
    "\n",
    "Forward Pass:\n",
    "\n",
    "Here the input data is passed through the neural network to obtain the predicted output.\n",
    "\n",
    "In forward pass, First calculate the output of the hidden layer.\n",
    "\n",
    "hidden_output = X•W1 + b1\n",
    "\n",
    "Then apply the sigmoid activation to the output.\n",
    "\n",
    "output = sigmoid( (X•W1) + b1)\n",
    "\n",
    "Backward Pass:\n",
    "\n",
    "First compute the gradients of the output layer.\n",
    "\n",
    "Loss = (y - output)\n",
    "\n",
    "Gradient of Loss = (y - output) * sigmoid_derivative(output)\n",
    "\n",
    "Now calculate d_W2 which is gradient of the loss function with respect to W2.\n",
    "\n",
    "d_W2 = hidden_output.T • Gradient of Loss\n",
    "\n",
    "Similarly calculate d_W1, d_b2 & d_b1\n",
    "\n",
    "dW1: Gradient of the loss function wrt W1\n",
    "\n",
    "d_b2: Gradient of the loss function wrt b2(bias of neuron in output layer)\n",
    "\n",
    "d_b1: Gradient of the loss function wrt b1(bias of neuron in hidden layer)\n",
    "\n",
    "Then Update the Weights:\n",
    "\n",
    "Here learning rate is the hyper parameter!\n",
    "\n",
    "A low learning rate can cause the model getting caught in local optima, while the high learning rate can cause the model to overshoot the general solution\n",
    "\n",
    "W1 += learning_rate * d_W1\n",
    "b1 += learning_rate * d_b1\n",
    "\n",
    "Now a method to train the neural network using both the forward and backward passes.\n",
    "\n",
    "The function will run for specified no of epochs, calculating:\n",
    "\n",
    "1. The Forward Pass\n",
    "2. Backward Pass\n",
    "3. Updating the Weights\n",
    "\n",
    "Finally the Predict Function\n",
    "\n",
    "Now to predict on any new data all we need to do is a single Forward Pass through the Network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "398011a2-c639-4422-9b72-8a5ae9f9d2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6aa40028-42f4-4b66-9388-f562a0d33cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        self.input_size=input_size\n",
    "        self.hidden_size=hidden_size\n",
    "        self.output_size=output_size\n",
    "        \n",
    "        self.W1=np.random.randn(self.input_size, self.hidden_size)\n",
    "        self.b1=np.zeros((1, self.hidden_size))\n",
    "        self.W2=np.random.randn(self.hidden_size, self.output_size)\n",
    "        self.b2=np.zeros((1, self.output_size))\n",
    "    \n",
    "    def sigmoid(self, x):\n",
    "        return 1/(1+ np.exp(-x))\n",
    "    \n",
    "    def sigmoid_derivative(self, x):\n",
    "        return x*(1-x)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        self.hidden_output=self.sigmoid(np.dot(X, self.W1) + self.b1)\n",
    "    \n",
    "        self.output=self.sigmoid(np.dot(self.hidden_output, self.W2)+ self.b2)\n",
    "        return self.output\n",
    "\n",
    "    def backward(self, X, y, learning_rate):\n",
    "        d_output=(y - self.output)*self.sigmoid_derivative(self.output)\n",
    "        d_W2=np.dot(self.hidden_output.T, d_output)\n",
    "        d_b2=np.sum(d_output, axis=0, keepdims=True)\n",
    "\n",
    "        d_hidden=np.dot(d_output, self.W2.T)*self.sigmoid_derivative(self.hidden_output)\n",
    "        d_W1=np.dot(X.T, d_hidden)\n",
    "        d_b1=np.sum(d_hidden, axis=0, keepdims=True)\n",
    "    \n",
    "        self.W2+=learning_rate*d_W2\n",
    "        self.b2+=learning_rate*d_b2\n",
    "        self.W1+=learning_rate*d_W1\n",
    "        self.b1+=learning_rate*d_b1\n",
    "        \n",
    "    def train(self, X, y, epochs, learning_rate):\n",
    "        for epoch in range(epochs):\n",
    "            output=self.forward(X)\n",
    "        \n",
    "            self.backward(X,y, learning_rate)\n",
    "        \n",
    "            loss=np.mean((y-output)**2)\n",
    "        \n",
    "    def predict(self, X):\n",
    "        return self.forward(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a95010-d942-4546-9af2-5fce528b284c",
   "metadata": {},
   "source": [
    "Example. Real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2c1ac825-d6da-4e6b-b5c7-4e689d694ed1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.88416012,  0.81152868],\n",
       "       [-0.96002879,  0.56556449],\n",
       "       [ 1.85874063, -0.00733803],\n",
       "       [ 0.00764831,  1.05233801],\n",
       "       [ 0.41849945, -0.5799713 ],\n",
       "       [ 0.13869329,  0.81585066],\n",
       "       [ 1.34215458, -0.51790117],\n",
       "       [ 1.75641418, -0.43888248],\n",
       "       [-0.77740569,  0.02605077],\n",
       "       [-0.03057186,  1.28527143],\n",
       "       [ 1.95392449,  0.31548605],\n",
       "       [-1.40805091,  0.24901532],\n",
       "       [ 0.60149834,  1.12853398],\n",
       "       [-0.17373403,  0.08702362],\n",
       "       [ 0.77983706,  0.5113426 ],\n",
       "       [ 1.12450899, -0.42540832],\n",
       "       [ 0.84391719,  0.6046485 ],\n",
       "       [ 0.34686366, -0.46010923],\n",
       "       [ 2.13531694,  0.65504985],\n",
       "       [ 0.74766545, -0.39166277],\n",
       "       [-1.78      , -1.71      ],\n",
       "       [-0.86      ,  0.66      ],\n",
       "       [ 1.95      , -0.073     ],\n",
       "       [ 0.76      ,  1.15      ],\n",
       "       [ 0.71      ,  1.97      ]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=np.array([[-0.88416012,  0.81152868],\n",
    "        [-0.96002879,  0.56556449],\n",
    "        [ 1.85874063, -0.00733803],\n",
    "        [ 0.00764831,  1.05233801],\n",
    "        [ 0.41849945, -0.5799713 ],\n",
    "        [ 0.13869329,  0.81585066],\n",
    "        [ 1.34215458, -0.51790117],\n",
    "        [ 1.75641418, -0.43888248],\n",
    "        [-0.77740569,  0.02605077],\n",
    "        [-0.03057186,  1.28527143],\n",
    "        [ 1.95392449,  0.31548605],\n",
    "        [-1.40805091,  0.24901532],\n",
    "        [ 0.60149834,  1.12853398],\n",
    "        [-0.17373403,  0.08702362],\n",
    "        [ 0.77983706,  0.5113426 ],\n",
    "        [ 1.12450899, -0.42540832],\n",
    "        [ 0.84391719,  0.6046485 ],\n",
    "        [ 0.34686366, -0.46010923],\n",
    "        [ 2.13531694,  0.65504985],\n",
    "        [ 0.74766545, -0.39166277],[-1.78,  -1.71],\n",
    "        [-0.86,  0.66],\n",
    "        [ 1.95, -0.073],\n",
    "        [ 0.76,  1.15],\n",
    "        [ 0.71, 1.97]])\n",
    "data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "03c792a2-07d8-487f-afa9-da5ea1f35e86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clasif=np.array([0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1])\n",
    "clasif"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098677e4-7e85-48ab-8c26-2d92afa254c6",
   "metadata": {},
   "source": [
    "I HAVE TO FINISH IT!!! LATER..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63826907-9f97-49fe-b24a-549d24332724",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
